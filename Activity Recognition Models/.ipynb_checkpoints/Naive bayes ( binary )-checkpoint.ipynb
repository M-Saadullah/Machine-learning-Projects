{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b157d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "from scipy.signal import welch\n",
    "from scipy.linalg import norm\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8326cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "ts_msAcc = np.load(\"testMSAccelerometer.npy\")\n",
    "ts_msGyr = np.load(\"testMSGyroscope.npy\")\n",
    "ts_labels = np.load(\"testLabels.npy\")\n",
    "\n",
    "OPEN_DOOR = 20\n",
    "RUB_HANDS = 36\n",
    "\n",
    "ts_labels_OPEN_DOOR_idx = ts_labels == OPEN_DOOR\n",
    "ts_labels_RUB_HANDS_idx = ts_labels == RUB_HANDS\n",
    "\n",
    "ts_msAcc_OPEN_DOOR = ts_msAcc[ts_labels_OPEN_DOOR_idx]\n",
    "ts_msGyr_OPEN_DOOR = ts_msGyr[ts_labels_OPEN_DOOR_idx]\n",
    "\n",
    "ts_msAcc_RUB_HANDS = ts_msAcc[ts_labels_RUB_HANDS_idx]\n",
    "ts_msGyr_RUB_HANDS = ts_msGyr[ts_labels_RUB_HANDS_idx]\n",
    "\n",
    "ts_labels_OPEN_DOOR = ts_labels[ts_labels_OPEN_DOOR_idx]\n",
    "ts_labels_RUB_HANDS = ts_labels[ts_labels_RUB_HANDS_idx]\n",
    "\n",
    "ts_msAcc_Two_Activities = np.concatenate((ts_msAcc_OPEN_DOOR, ts_msAcc_RUB_HANDS))\n",
    "ts_msGyr_Two_Activities = np.concatenate((ts_msGyr_OPEN_DOOR, ts_msGyr_RUB_HANDS))\n",
    "ts_labels_Two_Activities = np.concatenate((ts_labels_OPEN_DOOR, ts_labels_RUB_HANDS))\n",
    "\n",
    "np.save(\"test_MSAccelerometer_OpenDoor_RubHands.npy\", ts_msAcc_Two_Activities)\n",
    "np.save(\"test_MSGyroscope_OpenDoor_RubHands.npy\", ts_msGyr_Two_Activities)\n",
    "np.save(\"test_labels_OpenDoor_RubHands.npy\", ts_labels_Two_Activities)\n",
    "print(ts_labels_Two_Activities.shape[0])\n",
    "print(ts_labels_OPEN_DOOR.shape[0])\n",
    "print(ts_labels_RUB_HANDS.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d4a53f",
   "metadata": {},
   "source": [
    "### Extract Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09617396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "tr_msAcc = np.load(\"trainMSAccelerometer.npy\")\n",
    "tr_msGyr = np.load(\"trainMSGyroscope.npy\")\n",
    "tr_labels = np.load(\"trainLabels.npy\")\n",
    "\n",
    "OPEN_DOOR = 20\n",
    "RUB_HANDS = 36\n",
    "\n",
    "tr_labels_OPEN_DOOR_idx = tr_labels == OPEN_DOOR\n",
    "tr_labels_RUB_HANDS_idx = tr_labels == RUB_HANDS\n",
    "\n",
    "tr_msAcc_OPEN_DOOR = tr_msAcc[tr_labels_OPEN_DOOR_idx]\n",
    "tr_msGyr_OPEN_DOOR = tr_msGyr[tr_labels_OPEN_DOOR_idx]\n",
    "\n",
    "tr_msAcc_RUB_HANDS = tr_msAcc[tr_labels_RUB_HANDS_idx]\n",
    "tr_msGyr_RUB_HANDS = tr_msGyr[tr_labels_RUB_HANDS_idx]\n",
    "\n",
    "tr_labels_OPEN_DOOR = tr_labels[tr_labels_OPEN_DOOR_idx]\n",
    "tr_labels_RUB_HANDS = tr_labels[tr_labels_RUB_HANDS_idx]\n",
    "\n",
    "tr_msAcc_Two_Activities = np.concatenate((tr_msAcc_OPEN_DOOR, tr_msAcc_RUB_HANDS))\n",
    "tr_msGyr_Two_Activities = np.concatenate((tr_msGyr_OPEN_DOOR, tr_msGyr_RUB_HANDS))\n",
    "tr_labels_Two_Activities = np.concatenate((tr_labels_OPEN_DOOR, tr_labels_RUB_HANDS))\n",
    "\n",
    "np.save(\"train_MSAccelerometer_OpenDoor_RubHands.npy\", tr_msAcc_Two_Activities)\n",
    "np.save(\"train_MSGyroscope_OpenDoor_RubHands.npy\", tr_msGyr_Two_Activities)\n",
    "np.save(\"train_labels_OpenDoor_RubHands.npy\", tr_labels_Two_Activities)\n",
    "print(tr_labels_Two_Activities.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce93d57",
   "metadata": {},
   "source": [
    "### compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae9fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "def compute_features(data,tr_msAcc_Two_Activities):\n",
    "    for i in range(tr_msAcc_Two_Activities.shape[0]):\n",
    "        # Initialize an empty list to hold statistics for this sample\n",
    "        stats = []\n",
    "    \n",
    "        # Maximum\n",
    "        stats.append(np.max(tr_msAcc_Two_Activities[i], axis = 0))\n",
    "    \n",
    "        # Minimum\n",
    "        stats.append(np.min(tr_msAcc_Two_Activities[i], axis = 0))\n",
    "    \n",
    "        # First-order mean\n",
    "        mean_val = np.mean(tr_msAcc_Two_Activities[i], axis = 0)\n",
    "        stats.append(mean_val)\n",
    "    \n",
    "        # Standard Deviation\n",
    "        stats.append(np.std(tr_msAcc_Two_Activities[i], axis = 0))\n",
    "    \n",
    "        # Percentile 50\n",
    "        stats.append(np.percentile(tr_msAcc_Two_Activities[i], 50, axis = 0))\n",
    "    \n",
    "        # Percentile 80\n",
    "        stats.append(np.percentile(tr_msAcc_Two_Activities[i], 80, axis = 0))\n",
    "    \n",
    "        # Norm of the first-order mean\n",
    "        stats.append(np.full(mean_val.shape, norm(mean_val)))\n",
    "    \n",
    "        # Average (same as mean)\n",
    "        stats.append(mean_val)\n",
    "    \n",
    "        # Interquartile range\n",
    "        stats.append(np.percentile(tr_msAcc_Two_Activities[i], 75, axis = 0) - np.percentile(tr_msAcc_Two_Activities[i], 25, axis = 0))\n",
    "    \n",
    "        # Second-order mean\n",
    "        squared_mean = np.mean(np.square(tr_msAcc_Two_Activities[i]), axis = 0)\n",
    "        stats.append(squared_mean)\n",
    "    \n",
    "        # Skewness\n",
    "        stats.append(skew(tr_msAcc_Two_Activities[i], axis = 0))\n",
    "    \n",
    "        # Norm of the second-order mean\n",
    "        stats.append(np.full(squared_mean.shape, norm(squared_mean)))\n",
    "    \n",
    "        # Zero-crossing\n",
    "        zero_crossings = np.sum(np.diff(np.sign(tr_msAcc_Two_Activities[i]), axis = 0) != 0, axis = 0)\n",
    "        stats.append(zero_crossings)\n",
    "    \n",
    "        # Kurtosis\n",
    "        stats.append(kurtosis(tr_msAcc_Two_Activities[i], axis = 0))\n",
    "    \n",
    "        # Spectral energy\n",
    "        frequencies, power_spectral_density = welch(tr_msAcc_Two_Activities[i], axis = 0)\n",
    "        spectral_energy = np.sum(power_spectral_density, axis = 0)\n",
    "        stats.append(spectral_energy)\n",
    "    \n",
    "        # Percentile 20\n",
    "        stats.append(np.percentile(tr_msAcc_Two_Activities[i], 20, axis = 0))\n",
    "    \n",
    "        # Auto-correlation (assuming lag 1)\n",
    "        autocorr = np.array([acf(tr_msAcc_Two_Activities[i][:, j], nlags = 1, fft = True)[1] for j in range(tr_msAcc_Two_Activities[i].shape[1])])\n",
    "        stats.append(autocorr)\n",
    "    \n",
    "        # Spectral entropy\n",
    "        power_spectral_density /= np.sum(power_spectral_density, axis = 0, keepdims = True)\n",
    "        spectral_entropy = entropy(power_spectral_density, axis = 0)\n",
    "        stats.append(spectral_entropy)\n",
    "    \n",
    "        # Convert list of arrays to a 2D array of shape (18, 3)\n",
    "        stats_array = np.array(stats)\n",
    "    \n",
    "        # Store in pre-allocated data array\n",
    "        data[i] = stats_array\n",
    "    \n",
    "    # Now `data` contains the computed statistics for each sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85951221",
   "metadata": {},
   "source": [
    "### Training Data reshape and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1340c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty((tr_msAcc_Two_Activities.shape[0], 18, 3))\n",
    "compute_features(data,tr_msAcc_Two_Activities)\n",
    "# reshape the data so that each row contain all features of the one example(x-axis,y-axis,z-axis)\n",
    "data = np.reshape(data,(tr_msAcc_Two_Activities.shape[0],1,-1))\n",
    "data[0,0,:]\n",
    "print(data.shape)\n",
    "tr_msAcc_Two_Activities = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e4949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty((tr_msGyr_Two_Activities.shape[0], 18, 3))\n",
    "compute_features(data,tr_msGyr_Two_Activities)\n",
    "data = np.reshape(data,(tr_msGyr_Two_Activities.shape[0],1,-1))\n",
    "data[0,0,:]\n",
    "print(data.shape)\n",
    "tr_msGyr_Two_Activities = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b381ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate((tr_msAcc_Two_Activities, tr_msGyr_Two_Activities), axis=2)\n",
    "train_labels = tr_labels_Two_Activities\n",
    "\n",
    "train_data = np.squeeze(train_data, axis=1)\n",
    "train_labels = train_labels[:, np.newaxis]\n",
    "\n",
    "\n",
    "for i in range(train_data.shape[0]):\n",
    "    if train_labels[i] == 20:\n",
    "        train_labels[i] = 0;\n",
    "    elif train_labels[i] == 36:\n",
    "        train_labels[i] = 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ccbd2",
   "metadata": {},
   "source": [
    "### Test Data reshape and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty((ts_msAcc_Two_Activities.shape[0], 18, 3))\n",
    "compute_features(data,ts_msAcc_Two_Activities)\n",
    "# reshape the data so that each row contain all features of the one example(x-axis,y-axis,z-axis)\n",
    "data = np.reshape(data,(ts_msAcc_Two_Activities.shape[0],1,-1))\n",
    "data[0,0,:]\n",
    "print(data.shape)\n",
    "ts_msAcc_Two_Activities = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efc48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.empty((ts_msGyr_Two_Activities.shape[0], 18, 3))\n",
    "compute_features(data,ts_msGyr_Two_Activities)\n",
    "data = np.reshape(data,(ts_msGyr_Two_Activities.shape[0],1,-1))\n",
    "data[0,0,:]\n",
    "print(data.shape)\n",
    "ts_msGyr_Two_Activities = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2395e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.concatenate((ts_msAcc_Two_Activities, ts_msGyr_Two_Activities), axis = 2)\n",
    "test_labels = ts_labels_Two_Activities\n",
    "\n",
    "test_data = np.squeeze(test_data, axis = 1)\n",
    "test_labels = test_labels[:, np.newaxis]\n",
    "\n",
    "for i in range(test_data.shape[0]):\n",
    "    if test_labels[i] == 20:\n",
    "        test_labels[i] = 0;\n",
    "    elif test_labels[i] == 36:\n",
    "        test_labels[i] = 1;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30cdab7-f688-4276-a298-eb3aa6554fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizaion is one of the techniques of preprocessing of data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model = GaussianNB()\n",
    "nb_model.fit(train_data, train_labels)\n",
    "\n",
    "# Step 6: Make predictions\n",
    "y_pred = nb_model.predict(test_data)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "confusion_matrix = confusion_matrix(test_labels,y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Open Door', 'Rub Hands'], yticklabels=['Open Door', 'Rub Hands'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# F1 Score and Classification Report\n",
    "f1 = f1_score(test_labels, y_pred, average='weighted')\n",
    "print(f'Weighted F1 Score: {f1:.2f}')\n",
    "print('Classification Report:')\n",
    "print(classification_report(test_labels, y_pred, target_names=['Open Door', 'Rub Hands']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb98787b-6338-4d25-a097-c72471f427e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b687a1c-a67e-4340-921d-55ec0722e795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d39c657-d869-40e8-8b06-c9ca272f266d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
